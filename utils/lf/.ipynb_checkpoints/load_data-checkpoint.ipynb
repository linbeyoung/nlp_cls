{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "graphic-newman",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:39.464775Z",
     "start_time": "2021-06-14T07:57:39.457781Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regular-washington",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:41.110290Z",
     "start_time": "2021-06-14T07:57:39.857127Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liufeng\\.conda\\envs\\pytorch\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from data_loader import load_data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disturbed-recruitment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:41.956036Z",
     "start_time": "2021-06-14T07:57:41.946036Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_stopwords(path_to_file):\n",
    "    stop_words=set()\n",
    "    with open(path_to_file,encoding=\"utf-8\") as f:\n",
    "        content=f.readlines()\n",
    "    for word in content:\n",
    "        stop_words.add(word.strip('\\n'))\n",
    "        \n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cooked-wrist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:44.012739Z",
     "start_time": "2021-06-14T07:57:44.007744Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_sentence(sentence):\n",
    "    \"\"\"\n",
    "    分词，去停用词，返回一个列表\n",
    "    \"\"\"\n",
    "    result=[]\n",
    "    for word in jieba.lcut(sentence):\n",
    "        if word not in stop_words:\n",
    "            result.append(word)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neutral-greene",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:44.729057Z",
     "start_time": "2021-06-14T07:57:44.720044Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_word2vec(path_to_file):\n",
    "    print(\"加载词向量...\")\n",
    "    return gensim.models.KeyedVectors.load_word2vec_format(path_to_file,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "returning-experiment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:46.600095Z",
     "start_time": "2021-06-14T07:57:46.595095Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_vector(seed):\n",
    "    np.random.seed(seed)\n",
    "    vec=-1 + 2*np.random.random((300))\n",
    "    vec=vec.astype('float64')\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naked-outdoors",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:46.925951Z",
     "start_time": "2021-06-14T07:57:46.919943Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vector(word,seed=108):\n",
    "    try:\n",
    "        return word2vec[word]\n",
    "    except:\n",
    "        return random_vector(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regular-project",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:48.173980Z",
     "start_time": "2021-06-14T07:57:48.169972Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence2vector(word_list):\n",
    "    result=[]\n",
    "    for w in word_list:\n",
    "        result.append(get_vector(w))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "violent-latvia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:48.611399Z",
     "start_time": "2021-06-14T07:57:48.595399Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(dataset):\n",
    "    label=[]\n",
    "    for d in dataset:\n",
    "        if(d[1]!=5):\n",
    "            label.append(d[1])\n",
    "        else:\n",
    "            label.append(0)\n",
    "    label=np.array(label,dtype='uint8')\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "directed-prospect",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:57:51.125837Z",
     "start_time": "2021-06-14T07:57:51.108827Z"
    }
   },
   "outputs": [],
   "source": [
    "# 向量化\n",
    "def vectorize(dataset):\n",
    "    dataset_new=[]\n",
    "    for d in tqdm(dataset):\n",
    "        dataset_new.append(sentence2vector(cut_sentence(d[0])))\n",
    "        \n",
    "    return dataset_new\n",
    "\n",
    "# 截断和补0\n",
    "padding=np.zeros(300,dtype='float64')\n",
    "\n",
    "def unify(dataset,max_len):\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        if len(dataset[i])==max_len:\n",
    "            pass\n",
    "        elif len(dataset[i])<max_len:\n",
    "            while(len(dataset[i])!=max_len):\n",
    "                dataset[i].append(padding)\n",
    "        else:\n",
    "            dataset[i]=dataset[i][:max_len]\n",
    "            \n",
    "def array2np(dataset):\n",
    "    for index in tqdm(range(len(dataset))):\n",
    "        dataset[index]=np.array(dataset[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "greek-treasury",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T02:44:15.465605Z",
     "start_time": "2021-06-11T02:44:15.452403Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_mlp():\n",
    "    train,test=load_data('../../小组作业-语料/')\n",
    "    train_text=vectorize(train)\n",
    "    unify(train_text,30)\n",
    "    train_label=get_label(train)\n",
    "    \n",
    "    test_text=vectorize(test)\n",
    "    unify(test_text,30)\n",
    "    test_label=get_label(test)\n",
    "    \n",
    "    array2np(train_text)\n",
    "    array2np(test_text)\n",
    "    \n",
    "    return (np.array(train_text),train_label),(np.array(test_text),test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "separate-panic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:59:13.392899Z",
     "start_time": "2021-06-14T07:57:54.270616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载词向量...\n"
     ]
    }
   ],
   "source": [
    "stop_words=load_stopwords('../../src/hit_stopwords.txt')\n",
    "word2vec=load_word2vec('../../../sgns.zhihu.word.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "major-necessity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T07:59:13.471944Z",
     "start_time": "2021-06-14T07:59:13.394917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载完成，测试集比例0.2\n",
      "训练集37884条\n",
      "测试集9472条\n"
     ]
    }
   ],
   "source": [
    "train,test=load_data('../../小组作业-语料/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intelligent-accreditation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T08:14:43.080601Z",
     "start_time": "2021-06-14T08:14:36.827189Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\liufeng\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.591 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "37884it [00:06, 6067.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for index,_ in tqdm(enumerate(train)):\n",
    "    train[index][0]=cut_sentence(train[index][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "premier-holly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T08:14:54.655077Z",
     "start_time": "2021-06-14T08:14:54.640077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['赵薇', '扮相', '真', '好看', '知性', '优雅', '大气'], 5],\n",
       " [['不供', '时', '家破人亡'], 3],\n",
       " [['奶奶',\n",
       "   '一起',\n",
       "   '陈茶',\n",
       "   '带回家',\n",
       "   '虎皮',\n",
       "   '过去',\n",
       "   '玩',\n",
       "   '两个',\n",
       "   '人',\n",
       "   '坐',\n",
       "   '一起',\n",
       "   '看',\n",
       "   '虎皮',\n",
       "   '今天上午',\n",
       "   '才',\n",
       "   '碟片',\n",
       "   '店租',\n",
       "   '新',\n",
       "   '动漫'],\n",
       "  3],\n",
       " [['姥爷', '认错'], 3],\n",
       " [['故事', '平庸', '台词', '很', '有趣'], 5],\n",
       " [['影片',\n",
       "   '镜头',\n",
       "   '大自然',\n",
       "   '景色',\n",
       "   '之美',\n",
       "   '女主',\n",
       "   '容颜',\n",
       "   '之美',\n",
       "   '展现',\n",
       "   '淋漓尽致',\n",
       "   '近乎',\n",
       "   '默片',\n",
       "   '方式',\n",
       "   '演绎',\n",
       "   '无声',\n",
       "   '壮丽',\n",
       "   '同样',\n",
       "   '表达',\n",
       "   '影片',\n",
       "   '最后',\n",
       "   '核试验',\n",
       "   '大',\n",
       "   '爆炸',\n",
       "   '摧毁',\n",
       "   '美好',\n",
       "   '更是',\n",
       "   '肯定',\n",
       "   '这种',\n",
       "   '美的',\n",
       "   '不可',\n",
       "   '复制',\n",
       "   '绝对',\n",
       "   '俄罗斯',\n",
       "   '电影',\n",
       "   '文艺',\n",
       "   '之后',\n",
       "   '总是',\n",
       "   '痛处'],\n",
       "  5],\n",
       " [['不爱笑', '显然', '不', '欢迎'], 3],\n",
       " [['去',\n",
       "   '念',\n",
       "   '…',\n",
       "   '…',\n",
       "   '他往',\n",
       "   '许其琛',\n",
       "   '肩膀',\n",
       "   '上',\n",
       "   '许其琛',\n",
       "   '去',\n",
       "   '去',\n",
       "   '都',\n",
       "   '说好',\n",
       "   '估计',\n",
       "   '去',\n",
       "   '北京'],\n",
       "  3],\n",
       " [['沙特',\n",
       "   '通讯社',\n",
       "   '报道',\n",
       "   '当地',\n",
       "   '时间',\n",
       "   '3',\n",
       "   '月',\n",
       "   '27',\n",
       "   '日',\n",
       "   '沙特',\n",
       "   '皇家',\n",
       "   '空军',\n",
       "   '参加',\n",
       "   'Aces',\n",
       "   ' ',\n",
       "   'Meet',\n",
       "   ' ',\n",
       "   '2021',\n",
       "   '1',\n",
       "   '演习',\n",
       "   '所有',\n",
       "   '航空',\n",
       "   '技术',\n",
       "   '支援',\n",
       "   '人员',\n",
       "   '抵达',\n",
       "   '巴基斯坦',\n",
       "   '穆沙夫',\n",
       "   '空军基地',\n",
       "   'Mushaf',\n",
       "   ' ',\n",
       "   'air',\n",
       "   ' ',\n",
       "   'base'],\n",
       "  1],\n",
       " [['一拨儿', '住', '汉口', '一拨儿', '住', '武昌', '不', '顺路', '闸', '进站', '分开'], 3]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "advanced-stock",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T08:25:32.200433Z",
     "start_time": "2021-06-14T08:25:32.190928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "体育新闻： ['谈到', '球队', '失去', '德里克', '怀特', '表示']\n",
      "体育新闻： ['虎', '扑', '04', '月', '30', '日讯', '\\xa0', '今天', '比赛', '中', '火箭', '143', '136', '击败', '雄鹿']\n",
      "体育新闻： ['官方', '勒布朗', '詹姆斯', '今日', '比赛', '出战', '成疑', '_', '虎', '扑', 'NBA', '新闻']\n",
      "体育新闻： ['今日', '早上', '10', '00', '猛龙', '客场', '挑战', '爵士']\n",
      "体育新闻： ['谈到', '安德烈', '德', '拉蒙德', '安东尼', '戴维斯', '詹姆斯', '同场', '打球', '效果', '沃格尔', '说', '三人', '组合', '非常', '感到', '振奋', '很', '好', '回合', '节奏', '时机', '完全', '不', '到位', '互相', '熟悉', '需要', '时间', '一段', '调整期', '失利', '非常', '失望', '三人', '同场', '打球', '效果', '感觉', '很', '振奋']\n",
      "体育新闻： ['喜欢', '已经', '成为', '样子']\n",
      "体育新闻： ['卢', '今天', '伦纳德', '少', '7', '分钟', '乔治', '需', '保持', '进攻', '侵略性', '_', '虎', '扑', 'NBA', '新闻']\n",
      "体育新闻： ['这是', '拉塞尔', '威', '斯布鲁克', '本赛季', '常规赛', '31', '次', '三双']\n",
      "体育新闻： ['今天', '感觉', '好极了', '身体', '轻快', '很多']\n",
      "体育新闻： ['今晚', '打得', '很', '紧迫感', '对面', '一支', '出色', '球队']\n",
      "晋江小说： ['不供', '时', '家破人亡']\n",
      "晋江小说： ['奶奶', '一起', '陈茶', '带回家', '虎皮', '过去', '玩', '两个', '人', '坐', '一起', '看', '虎皮', '今天上午', '才', '碟片', '店租', '新', '动漫']\n",
      "晋江小说： ['姥爷', '认错']\n",
      "晋江小说： ['不爱笑', '显然', '不', '欢迎']\n",
      "晋江小说： ['去', '念', '…', '…', '他往', '许其琛', '肩膀', '上', '许其琛', '去', '去', '都', '说好', '估计', '去', '北京']\n",
      "晋江小说： ['一拨儿', '住', '汉口', '一拨儿', '住', '武昌', '不', '顺路', '闸', '进站', '分开']\n",
      "晋江小说： ['最', '典型', '孟星哲', '以为', '考得', '巨好', '自信', '要死', '成绩', '垫底']\n",
      "晋江小说： ['奶奶', '薛宥卡', '走', '一会儿', '借着', '边路', '熟悉', '很快', '找到', '宅邸']\n",
      "晋江小说： ['班', '丫头', '眼光', '好', '多人', '挑', '中', '云庆帝', '伸手', '指', '指容', '瑕', '班恒', '都', '眼光']\n",
      "晋江小说： ['厉随落', '平地上', '占用', '一点', '宝贵', '杀人', '时间', '耐心', '搞', '教育', '捂', '眼睛']\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for t in train:\n",
    "    if t[1]==2 and count<10:\n",
    "        count+=1\n",
    "        print('体育新闻：',t[0])\n",
    "\n",
    "    if count==10:\n",
    "        break\n",
    "        \n",
    "count=0\n",
    "for t in train:\n",
    "    if t[1]==3 and count<10:\n",
    "        count+=1\n",
    "        print('晋江小说：',t[0])\n",
    "\n",
    "    if count==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-exhaust",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
